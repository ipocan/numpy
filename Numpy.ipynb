{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Array Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "print(a)\n",
    "\n",
    "#number of dimensions\n",
    "print(a.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "b = np.array([[1,2,3],[4,5,6]])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float64'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.array([1.1,3.3,4.6])\n",
    "c.dtype.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1, 3.3, 4.6])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "d = np.zeros((2,3))\n",
    "print(d)\n",
    "\n",
    "e = np.ones((2,3))\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.32876556, 0.08074557, 0.35189857],\n",
       "       [0.66807475, 0.82530267, 0.04970593]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.random.rand(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42,\n",
       "       44, 46, 48])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = np.arange(10,50,2)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.0952381 , 0.19047619, 0.28571429, 0.38095238,\n",
       "       0.47619048, 0.57142857, 0.66666667, 0.76190476, 0.85714286,\n",
       "       0.95238095, 1.04761905, 1.14285714, 1.23809524, 1.33333333,\n",
       "       1.42857143, 1.52380952, 1.61904762, 1.71428571, 1.80952381,\n",
       "       1.9047619 , 2.        ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0,2,22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Array Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9 18 27 36]\n",
      "[ 10  40  90 160]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([10,20,30,40])\n",
    "b = np.array([1,2,3,4])\n",
    "\n",
    "c = a-b\n",
    "print(c)\n",
    "\n",
    "d = a*b\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-17.22222222, -22.77777778, -20.        , -25.55555556,\n",
       "       -17.22222222])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fahrenheit = np.array([0,-10,-5,-15,0])\n",
    "celcius = (fahrenheit - 31)*(5/9)\n",
    "celcius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False,  True])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celcius > -20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, False, False])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celcius%2 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0]\n",
      " [0 4]]\n",
      "[[5 4]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,1],[0,1]])\n",
    "B = np.array([[2,0],[3,4]])\n",
    "\n",
    "#elementwise product\n",
    "print(A*B)\n",
    "\n",
    "#matrix product\n",
    "print(A@B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# when manipulating arrays of different types, the type of the resulting array will correspond\n",
    "#to the more general of the two types. This is calles upcasting\n",
    "\n",
    "#Let's create an array of integers\n",
    "array1 = np.array([[1,2,3],[7,8,9]])\n",
    "print(array1.dtype)\n",
    "\n",
    "array2 = np.array([[1.1,2.2,3.3],[6.7,8.9,0.1]])\n",
    "print(array2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.1  4.2  6.3]\n",
      " [13.7 16.9  9.1]]\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "array3 = array1+array2\n",
    "print(array3)\n",
    "print(array3.dtype)\n",
    "\n",
    "#results upcastes to the floating numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.300000000000004\n",
      "8.9\n",
      "0.1\n",
      "3.7166666666666672\n"
     ]
    }
   ],
   "source": [
    "print(array2.sum())\n",
    "print(array2.max())\n",
    "print(array2.min())\n",
    "print(array2.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4  5]\n",
      " [ 6  7  8  9 10]\n",
      " [11 12 13 14 15]]\n"
     ]
    }
   ],
   "source": [
    "b = np.arange(1,16,1).reshape(3,5)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=P size=335x150 at 0x7FEC22205FA0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "im = Image.open('numpy.png')\n",
    "display(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 335)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, we can convert this PIL to a numpty array.\n",
    "array= np.array(im)\n",
    "print(array.shape)\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       ...,\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.full(array.shape,255)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_array = array-mask\n",
    "modified_array = modified_array* -1\n",
    "modified_array = modified_array.astype(np.unint8)\n",
    "modified_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image.fromarray(modified_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped = np.reshape(modified_array,(100,400))\n",
    "print(reshaped.shape)\n",
    "display(Image.fromarray(reshaped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing, Slicing and Iterating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "a[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2],[5,6],[7,6],[3,8]])\n",
    "a[2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 8, 1])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([a[2,1],a[3,1],a[0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 6 6]\n"
     ]
    }
   ],
   "source": [
    "print(a[[0,1,2],[0,1,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False]\n",
      " [False  True]\n",
      " [ True  True]\n",
      " [False  True]]\n"
     ]
    }
   ],
   "source": [
    "print(a>5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 7 6 8]\n"
     ]
    }
   ],
   "source": [
    "print(a[a>5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5,6,7])\n",
    "print(a[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 5]\n"
     ]
    }
   ],
   "source": [
    "print(a[2:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [4, 5, 6, 7],\n",
       "       [6, 5, 4, 3]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3,4],[4,5,6,7],[6,5,4,3]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [4, 5, 6, 7]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:2, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub array index [0,0] values before change:  2\n",
      "sub array index [0,0] value after change:  50\n",
      "original array index [0,1] value after change:  50\n"
     ]
    }
   ],
   "source": [
    "sub_array = a[:2, 1:3]\n",
    "print(\"sub array index [0,0] values before change: \", sub_array[0,0])\n",
    "sub_array[0,0] = 50\n",
    "print(\"sub array index [0,0] value after change: \", sub_array[0,0])\n",
    "print(\"original array index [0,1] value after change: \",a[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Numpy with Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.4  ,  0.7  ,  0.   , ...,  0.56 ,  9.4  ,  5.   ],\n",
       "       [ 7.8  ,  0.88 ,  0.   , ...,  0.68 ,  9.8  ,  5.   ],\n",
       "       [ 7.8  ,  0.76 ,  0.04 , ...,  0.65 ,  9.8  ,  5.   ],\n",
       "       ...,\n",
       "       [ 6.3  ,  0.51 ,  0.13 , ...,  0.75 , 11.   ,  6.   ],\n",
       "       [ 5.9  ,  0.645,  0.12 , ...,  0.71 , 10.2  ,  5.   ],\n",
       "       [ 6.   ,  0.31 ,  0.47 , ...,  0.66 , 11.   ,  6.   ]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to load  a dataset in Numpy, we can use the genfromtxt() function.\n",
    "\n",
    "wines = np.genfromtxt('winequality-red.csv',delimiter=\";\",skip_header=1)\n",
    "wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one integer 0 for slicing []\n",
      "0 to 1 for slicing : \n",
      " [[7.4]\n",
      " [7.8]\n",
      " [7.8]\n",
      " ...\n",
      " [6.3]\n",
      " [5.9]\n",
      " [6. ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"one integer 0 for slicing\", wines[:0])\n",
    "print(\"0 to 1 for slicing : \\n\", wines[:,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.4  , 0.7  , 0.   ],\n",
       "       [7.8  , 0.88 , 0.   ],\n",
       "       [7.8  , 0.76 , 0.04 ],\n",
       "       ...,\n",
       "       [6.3  , 0.51 , 0.13 ],\n",
       "       [5.9  , 0.645, 0.12 ],\n",
       "       [6.   , 0.31 , 0.47 ]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines[:, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.076, 0.7  ],\n",
       "       [0.   , 0.098, 0.88 ],\n",
       "       [0.04 , 0.092, 0.76 ],\n",
       "       ...,\n",
       "       [0.13 , 0.076, 0.51 ],\n",
       "       [0.12 , 0.075, 0.645],\n",
       "       [0.47 , 0.067, 0.31 ]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines[:,[2,4,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.6360225140712945"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines[:, -1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(  1, 337, 118, 4, 4.5, 4.5, 9.65, 1, 0.92),\n",
       "       (  2, 324, 107, 4, 4. , 4.5, 8.87, 1, 0.76),\n",
       "       (  3, 316, 104, 3, 3. , 3.5, 8.  , 1, 0.72),\n",
       "       (  4, 322, 110, 3, 3.5, 2.5, 8.67, 1, 0.8 ),\n",
       "       (  5, 314, 103, 2, 2. , 3. , 8.21, 0, 0.65),\n",
       "       (  6, 330, 115, 5, 4.5, 3. , 9.34, 1, 0.9 ),\n",
       "       (  7, 321, 109, 3, 3. , 4. , 8.2 , 1, 0.75),\n",
       "       (  8, 308, 101, 2, 3. , 4. , 7.9 , 0, 0.68),\n",
       "       (  9, 302, 102, 1, 2. , 1.5, 8.  , 0, 0.5 ),\n",
       "       ( 10, 323, 108, 3, 3.5, 3. , 8.6 , 0, 0.45),\n",
       "       ( 11, 325, 106, 3, 3.5, 4. , 8.4 , 1, 0.52),\n",
       "       ( 12, 327, 111, 4, 4. , 4.5, 9.  , 1, 0.84),\n",
       "       ( 13, 328, 112, 4, 4. , 4.5, 9.1 , 1, 0.78),\n",
       "       ( 14, 307, 109, 3, 4. , 3. , 8.  , 1, 0.62),\n",
       "       ( 15, 311, 104, 3, 3.5, 2. , 8.2 , 1, 0.61),\n",
       "       ( 16, 314, 105, 3, 3.5, 2.5, 8.3 , 0, 0.54),\n",
       "       ( 17, 317, 107, 3, 4. , 3. , 8.7 , 0, 0.66),\n",
       "       ( 18, 319, 106, 3, 4. , 3. , 8.  , 1, 0.65),\n",
       "       ( 19, 318, 110, 3, 4. , 3. , 8.8 , 0, 0.63),\n",
       "       ( 20, 303, 102, 3, 3.5, 3. , 8.5 , 0, 0.62),\n",
       "       ( 21, 312, 107, 3, 3. , 2. , 7.9 , 1, 0.64),\n",
       "       ( 22, 325, 114, 4, 3. , 2. , 8.4 , 0, 0.7 ),\n",
       "       ( 23, 328, 116, 5, 5. , 5. , 9.5 , 1, 0.94),\n",
       "       ( 24, 334, 119, 5, 5. , 4.5, 9.7 , 1, 0.95),\n",
       "       ( 25, 336, 119, 5, 4. , 3.5, 9.8 , 1, 0.97),\n",
       "       ( 26, 340, 120, 5, 4.5, 4.5, 9.6 , 1, 0.94),\n",
       "       ( 27, 322, 109, 5, 4.5, 3.5, 8.8 , 0, 0.76),\n",
       "       ( 28, 298,  98, 2, 1.5, 2.5, 7.5 , 1, 0.44),\n",
       "       ( 29, 295,  93, 1, 2. , 2. , 7.2 , 0, 0.46),\n",
       "       ( 30, 310,  99, 2, 1.5, 2. , 7.3 , 0, 0.54),\n",
       "       ( 31, 300,  97, 2, 3. , 3. , 8.1 , 1, 0.65),\n",
       "       ( 32, 327, 103, 3, 4. , 4. , 8.3 , 1, 0.74),\n",
       "       ( 33, 338, 118, 4, 3. , 4.5, 9.4 , 1, 0.91),\n",
       "       ( 34, 340, 114, 5, 4. , 4. , 9.6 , 1, 0.9 ),\n",
       "       ( 35, 331, 112, 5, 4. , 5. , 9.8 , 1, 0.94),\n",
       "       ( 36, 320, 110, 5, 5. , 5. , 9.2 , 1, 0.88),\n",
       "       ( 37, 299, 106, 2, 4. , 4. , 8.4 , 0, 0.64),\n",
       "       ( 38, 300, 105, 1, 1. , 2. , 7.8 , 0, 0.58),\n",
       "       ( 39, 304, 105, 1, 3. , 1.5, 7.5 , 0, 0.52),\n",
       "       ( 40, 307, 108, 2, 4. , 3.5, 7.7 , 0, 0.48),\n",
       "       ( 41, 308, 110, 3, 3.5, 3. , 8.  , 1, 0.46),\n",
       "       ( 42, 316, 105, 2, 2.5, 2.5, 8.2 , 1, 0.49),\n",
       "       ( 43, 313, 107, 2, 2.5, 2. , 8.5 , 1, 0.53),\n",
       "       ( 44, 332, 117, 4, 4.5, 4. , 9.1 , 0, 0.87),\n",
       "       ( 45, 326, 113, 5, 4.5, 4. , 9.4 , 1, 0.91),\n",
       "       ( 46, 322, 110, 5, 5. , 4. , 9.1 , 1, 0.88),\n",
       "       ( 47, 329, 114, 5, 4. , 5. , 9.3 , 1, 0.86),\n",
       "       ( 48, 339, 119, 5, 4.5, 4. , 9.7 , 0, 0.89),\n",
       "       ( 49, 321, 110, 3, 3.5, 5. , 8.85, 1, 0.82),\n",
       "       ( 50, 327, 111, 4, 3. , 4. , 8.4 , 1, 0.78),\n",
       "       ( 51, 313,  98, 3, 2.5, 4.5, 8.3 , 1, 0.76),\n",
       "       ( 52, 312, 100, 2, 1.5, 3.5, 7.9 , 1, 0.56),\n",
       "       ( 53, 334, 116, 4, 4. , 3. , 8.  , 1, 0.78),\n",
       "       ( 54, 324, 112, 4, 4. , 2.5, 8.1 , 1, 0.72),\n",
       "       ( 55, 322, 110, 3, 3. , 3.5, 8.  , 0, 0.7 ),\n",
       "       ( 56, 320, 103, 3, 3. , 3. , 7.7 , 0, 0.64),\n",
       "       ( 57, 316, 102, 3, 2. , 3. , 7.4 , 0, 0.64),\n",
       "       ( 58, 298,  99, 2, 4. , 2. , 7.6 , 0, 0.46),\n",
       "       ( 59, 300,  99, 1, 3. , 2. , 6.8 , 1, 0.36),\n",
       "       ( 60, 311, 104, 2, 2. , 2. , 8.3 , 0, 0.42),\n",
       "       ( 61, 309, 100, 2, 3. , 3. , 8.1 , 0, 0.48),\n",
       "       ( 62, 307, 101, 3, 4. , 3. , 8.2 , 0, 0.47),\n",
       "       ( 63, 304, 105, 2, 3. , 3. , 8.2 , 1, 0.54),\n",
       "       ( 64, 315, 107, 2, 4. , 3. , 8.5 , 1, 0.56),\n",
       "       ( 65, 325, 111, 3, 3. , 3.5, 8.7 , 0, 0.52),\n",
       "       ( 66, 325, 112, 4, 3.5, 3.5, 8.92, 0, 0.55),\n",
       "       ( 67, 327, 114, 3, 3. , 3. , 9.02, 0, 0.61),\n",
       "       ( 68, 316, 107, 2, 3.5, 3.5, 8.64, 1, 0.57),\n",
       "       ( 69, 318, 109, 3, 3.5, 4. , 9.22, 1, 0.68),\n",
       "       ( 70, 328, 115, 4, 4.5, 4. , 9.16, 1, 0.78),\n",
       "       ( 71, 332, 118, 5, 5. , 5. , 9.64, 1, 0.94),\n",
       "       ( 72, 336, 112, 5, 5. , 5. , 9.76, 1, 0.96),\n",
       "       ( 73, 321, 111, 5, 5. , 5. , 9.45, 1, 0.93),\n",
       "       ( 74, 314, 108, 4, 4.5, 4. , 9.04, 1, 0.84),\n",
       "       ( 75, 314, 106, 3, 3. , 5. , 8.9 , 0, 0.74),\n",
       "       ( 76, 329, 114, 2, 2. , 4. , 8.56, 1, 0.72),\n",
       "       ( 77, 327, 112, 3, 3. , 3. , 8.72, 1, 0.74),\n",
       "       ( 78, 301,  99, 2, 3. , 2. , 8.22, 0, 0.64),\n",
       "       ( 79, 296,  95, 2, 3. , 2. , 7.54, 1, 0.44),\n",
       "       ( 80, 294,  93, 1, 1.5, 2. , 7.36, 0, 0.46),\n",
       "       ( 81, 312, 105, 3, 2. , 3. , 8.02, 1, 0.5 ),\n",
       "       ( 82, 340, 120, 4, 5. , 5. , 9.5 , 1, 0.96),\n",
       "       ( 83, 320, 110, 5, 5. , 4.5, 9.22, 1, 0.92),\n",
       "       ( 84, 322, 115, 5, 4. , 4.5, 9.36, 1, 0.92),\n",
       "       ( 85, 340, 115, 5, 4.5, 4.5, 9.45, 1, 0.94),\n",
       "       ( 86, 319, 103, 4, 4.5, 3.5, 8.66, 0, 0.76),\n",
       "       ( 87, 315, 106, 3, 4.5, 3.5, 8.42, 0, 0.72),\n",
       "       ( 88, 317, 107, 2, 3.5, 3. , 8.28, 0, 0.66),\n",
       "       ( 89, 314, 108, 3, 4.5, 3.5, 8.14, 0, 0.64),\n",
       "       ( 90, 316, 109, 4, 4.5, 3.5, 8.76, 1, 0.74),\n",
       "       ( 91, 318, 106, 2, 4. , 4. , 7.92, 1, 0.64),\n",
       "       ( 92, 299,  97, 3, 5. , 3.5, 7.66, 0, 0.38),\n",
       "       ( 93, 298,  98, 2, 4. , 3. , 8.03, 0, 0.34),\n",
       "       ( 94, 301,  97, 2, 3. , 3. , 7.88, 1, 0.44),\n",
       "       ( 95, 303,  99, 3, 2. , 2.5, 7.66, 0, 0.36),\n",
       "       ( 96, 304, 100, 4, 1.5, 2.5, 7.84, 0, 0.42),\n",
       "       ( 97, 306, 100, 2, 3. , 3. , 8.  , 0, 0.48),\n",
       "       ( 98, 331, 120, 3, 4. , 4. , 8.96, 1, 0.86),\n",
       "       ( 99, 332, 119, 4, 5. , 4.5, 9.24, 1, 0.9 ),\n",
       "       (100, 323, 113, 3, 4. , 4. , 8.88, 1, 0.79),\n",
       "       (101, 322, 107, 3, 3.5, 3.5, 8.46, 1, 0.71),\n",
       "       (102, 312, 105, 2, 2.5, 3. , 8.12, 0, 0.64),\n",
       "       (103, 314, 106, 2, 4. , 3.5, 8.25, 0, 0.62),\n",
       "       (104, 317, 104, 2, 4.5, 4. , 8.47, 0, 0.57),\n",
       "       (105, 326, 112, 3, 3.5, 3. , 9.05, 1, 0.74),\n",
       "       (106, 316, 110, 3, 4. , 4.5, 8.78, 1, 0.69),\n",
       "       (107, 329, 111, 4, 4.5, 4.5, 9.18, 1, 0.87),\n",
       "       (108, 338, 117, 4, 3.5, 4.5, 9.46, 1, 0.91),\n",
       "       (109, 331, 116, 5, 5. , 5. , 9.38, 1, 0.93),\n",
       "       (110, 304, 103, 5, 5. , 4. , 8.64, 0, 0.68),\n",
       "       (111, 305, 108, 5, 3. , 3. , 8.48, 0, 0.61),\n",
       "       (112, 321, 109, 4, 4. , 4. , 8.68, 1, 0.69),\n",
       "       (113, 301, 107, 3, 3.5, 3.5, 8.34, 1, 0.62),\n",
       "       (114, 320, 110, 2, 4. , 3.5, 8.56, 0, 0.72),\n",
       "       (115, 311, 105, 3, 3.5, 3. , 8.45, 1, 0.59),\n",
       "       (116, 310, 106, 4, 4.5, 4.5, 9.04, 1, 0.66),\n",
       "       (117, 299, 102, 3, 4. , 3.5, 8.62, 0, 0.56),\n",
       "       (118, 290, 104, 4, 2. , 2.5, 7.46, 0, 0.45),\n",
       "       (119, 296,  99, 2, 3. , 3.5, 7.28, 0, 0.47),\n",
       "       (120, 327, 104, 5, 3. , 3.5, 8.84, 1, 0.71),\n",
       "       (121, 335, 117, 5, 5. , 5. , 9.56, 1, 0.94),\n",
       "       (122, 334, 119, 5, 4.5, 4.5, 9.48, 1, 0.94),\n",
       "       (123, 310, 106, 4, 1.5, 2.5, 8.36, 0, 0.57),\n",
       "       (124, 308, 108, 3, 3.5, 3.5, 8.22, 0, 0.61),\n",
       "       (125, 301, 106, 4, 2.5, 3. , 8.47, 0, 0.57),\n",
       "       (126, 300, 100, 3, 2. , 3. , 8.66, 1, 0.64),\n",
       "       (127, 323, 113, 3, 4. , 3. , 9.32, 1, 0.85),\n",
       "       (128, 319, 112, 3, 2.5, 2. , 8.71, 1, 0.78),\n",
       "       (129, 326, 112, 3, 3.5, 3. , 9.1 , 1, 0.84),\n",
       "       (130, 333, 118, 5, 5. , 5. , 9.35, 1, 0.92),\n",
       "       (131, 339, 114, 5, 4. , 4.5, 9.76, 1, 0.96),\n",
       "       (132, 303, 105, 5, 5. , 4.5, 8.65, 0, 0.77),\n",
       "       (133, 309, 105, 5, 3.5, 3.5, 8.56, 0, 0.71),\n",
       "       (134, 323, 112, 5, 4. , 4.5, 8.78, 0, 0.79),\n",
       "       (135, 333, 113, 5, 4. , 4. , 9.28, 1, 0.89),\n",
       "       (136, 314, 109, 4, 3.5, 4. , 8.77, 1, 0.82),\n",
       "       (137, 312, 103, 3, 5. , 4. , 8.45, 0, 0.76),\n",
       "       (138, 316, 100, 2, 1.5, 3. , 8.16, 1, 0.71),\n",
       "       (139, 326, 116, 2, 4.5, 3. , 9.08, 1, 0.8 ),\n",
       "       (140, 318, 109, 1, 3.5, 3.5, 9.12, 0, 0.78),\n",
       "       (141, 329, 110, 2, 4. , 3. , 9.15, 1, 0.84),\n",
       "       (142, 332, 118, 2, 4.5, 3.5, 9.36, 1, 0.9 ),\n",
       "       (143, 331, 115, 5, 4. , 3.5, 9.44, 1, 0.92),\n",
       "       (144, 340, 120, 4, 4.5, 4. , 9.92, 1, 0.97),\n",
       "       (145, 325, 112, 2, 3. , 3.5, 8.96, 1, 0.8 ),\n",
       "       (146, 320, 113, 2, 2. , 2.5, 8.64, 1, 0.81),\n",
       "       (147, 315, 105, 3, 2. , 2.5, 8.48, 0, 0.75),\n",
       "       (148, 326, 114, 3, 3. , 3. , 9.11, 1, 0.83),\n",
       "       (149, 339, 116, 4, 4. , 3.5, 9.8 , 1, 0.96),\n",
       "       (150, 311, 106, 2, 3.5, 3. , 8.26, 1, 0.79),\n",
       "       (151, 334, 114, 4, 4. , 4. , 9.43, 1, 0.93),\n",
       "       (152, 332, 116, 5, 5. , 5. , 9.28, 1, 0.94),\n",
       "       (153, 321, 112, 5, 5. , 5. , 9.06, 1, 0.86),\n",
       "       (154, 324, 105, 3, 3. , 4. , 8.75, 0, 0.79),\n",
       "       (155, 326, 108, 3, 3. , 3.5, 8.89, 0, 0.8 ),\n",
       "       (156, 312, 109, 3, 3. , 3. , 8.69, 0, 0.77),\n",
       "       (157, 315, 105, 3, 2. , 2.5, 8.34, 0, 0.7 ),\n",
       "       (158, 309, 104, 2, 2. , 2.5, 8.26, 0, 0.65),\n",
       "       (159, 306, 106, 2, 2. , 2.5, 8.14, 0, 0.61),\n",
       "       (160, 297, 100, 1, 1.5, 2. , 7.9 , 0, 0.52),\n",
       "       (161, 315, 103, 1, 1.5, 2. , 7.86, 0, 0.57),\n",
       "       (162, 298,  99, 1, 1.5, 3. , 7.46, 0, 0.53),\n",
       "       (163, 318, 109, 3, 3. , 3. , 8.5 , 0, 0.67),\n",
       "       (164, 317, 105, 3, 3.5, 3. , 8.56, 0, 0.68),\n",
       "       (165, 329, 111, 4, 4.5, 4. , 9.01, 1, 0.81),\n",
       "       (166, 322, 110, 5, 4.5, 4. , 8.97, 0, 0.78),\n",
       "       (167, 302, 102, 3, 3.5, 5. , 8.33, 0, 0.65),\n",
       "       (168, 313, 102, 3, 2. , 3. , 8.27, 0, 0.64),\n",
       "       (169, 293,  97, 2, 2. , 4. , 7.8 , 1, 0.64),\n",
       "       (170, 311,  99, 2, 2.5, 3. , 7.98, 0, 0.65),\n",
       "       (171, 312, 101, 2, 2.5, 3.5, 8.04, 1, 0.68),\n",
       "       (172, 334, 117, 5, 4. , 4.5, 9.07, 1, 0.89),\n",
       "       (173, 322, 110, 4, 4. , 5. , 9.13, 1, 0.86),\n",
       "       (174, 323, 113, 4, 4. , 4.5, 9.23, 1, 0.89),\n",
       "       (175, 321, 111, 4, 4. , 4. , 8.97, 1, 0.87),\n",
       "       (176, 320, 111, 4, 4.5, 3.5, 8.87, 1, 0.85),\n",
       "       (177, 329, 119, 4, 4.5, 4.5, 9.16, 1, 0.9 ),\n",
       "       (178, 319, 110, 3, 3.5, 3.5, 9.04, 0, 0.82),\n",
       "       (179, 309, 108, 3, 2.5, 3. , 8.12, 0, 0.72),\n",
       "       (180, 307, 102, 3, 3. , 3. , 8.27, 0, 0.73),\n",
       "       (181, 300, 104, 3, 3.5, 3. , 8.16, 0, 0.71),\n",
       "       (182, 305, 107, 2, 2.5, 2.5, 8.42, 0, 0.71),\n",
       "       (183, 299, 100, 2, 3. , 3.5, 7.88, 0, 0.68),\n",
       "       (184, 314, 110, 3, 4. , 4. , 8.8 , 0, 0.75),\n",
       "       (185, 316, 106, 2, 2.5, 4. , 8.32, 0, 0.72),\n",
       "       (186, 327, 113, 4, 4.5, 4.5, 9.11, 1, 0.89),\n",
       "       (187, 317, 107, 3, 3.5, 3. , 8.68, 1, 0.84),\n",
       "       (188, 335, 118, 5, 4.5, 3.5, 9.44, 1, 0.93),\n",
       "       (189, 331, 115, 5, 4.5, 3.5, 9.36, 1, 0.93),\n",
       "       (190, 324, 112, 5, 5. , 5. , 9.08, 1, 0.88),\n",
       "       (191, 324, 111, 5, 4.5, 4. , 9.16, 1, 0.9 ),\n",
       "       (192, 323, 110, 5, 4. , 5. , 8.98, 1, 0.87),\n",
       "       (193, 322, 114, 5, 4.5, 4. , 8.94, 1, 0.86),\n",
       "       (194, 336, 118, 5, 4.5, 5. , 9.53, 1, 0.94),\n",
       "       (195, 316, 109, 3, 3.5, 3. , 8.76, 0, 0.77),\n",
       "       (196, 307, 107, 2, 3. , 3.5, 8.52, 1, 0.78),\n",
       "       (197, 306, 105, 2, 3. , 2.5, 8.26, 0, 0.73),\n",
       "       (198, 310, 106, 2, 3.5, 2.5, 8.33, 0, 0.73),\n",
       "       (199, 311, 104, 3, 4.5, 4.5, 8.43, 0, 0.7 ),\n",
       "       (200, 313, 107, 3, 4. , 4.5, 8.69, 0, 0.72),\n",
       "       (201, 317, 103, 3, 2.5, 3. , 8.54, 1, 0.73),\n",
       "       (202, 315, 110, 2, 3.5, 3. , 8.46, 1, 0.72),\n",
       "       (203, 340, 120, 5, 4.5, 4.5, 9.91, 1, 0.97),\n",
       "       (204, 334, 120, 5, 4. , 5. , 9.87, 1, 0.97),\n",
       "       (205, 298, 105, 3, 3.5, 4. , 8.54, 0, 0.69),\n",
       "       (206, 295,  99, 2, 2.5, 3. , 7.65, 0, 0.57),\n",
       "       (207, 315,  99, 2, 3.5, 3. , 7.89, 0, 0.63),\n",
       "       (208, 310, 102, 3, 3.5, 4. , 8.02, 1, 0.66),\n",
       "       (209, 305, 106, 2, 3. , 3. , 8.16, 0, 0.64),\n",
       "       (210, 301, 104, 3, 3.5, 4. , 8.12, 1, 0.68),\n",
       "       (211, 325, 108, 4, 4.5, 4. , 9.06, 1, 0.79),\n",
       "       (212, 328, 110, 4, 5. , 4. , 9.14, 1, 0.82),\n",
       "       (213, 338, 120, 4, 5. , 5. , 9.66, 1, 0.95),\n",
       "       (214, 333, 119, 5, 5. , 4.5, 9.78, 1, 0.96),\n",
       "       (215, 331, 117, 4, 4.5, 5. , 9.42, 1, 0.94),\n",
       "       (216, 330, 116, 5, 5. , 4.5, 9.36, 1, 0.93),\n",
       "       (217, 322, 112, 4, 4.5, 4.5, 9.26, 1, 0.91),\n",
       "       (218, 321, 109, 4, 4. , 4. , 9.13, 1, 0.85),\n",
       "       (219, 324, 110, 4, 3. , 3.5, 8.97, 1, 0.84),\n",
       "       (220, 312, 104, 3, 3.5, 3.5, 8.42, 0, 0.74),\n",
       "       (221, 313, 103, 3, 4. , 4. , 8.75, 0, 0.76),\n",
       "       (222, 316, 110, 3, 3.5, 4. , 8.56, 0, 0.75),\n",
       "       (223, 324, 113, 4, 4.5, 4. , 8.79, 0, 0.76),\n",
       "       (224, 308, 109, 2, 3. , 4. , 8.45, 0, 0.71),\n",
       "       (225, 305, 105, 2, 3. , 2. , 8.23, 0, 0.67),\n",
       "       (226, 296,  99, 2, 2.5, 2.5, 8.03, 0, 0.61),\n",
       "       (227, 306, 110, 2, 3.5, 4. , 8.45, 0, 0.63),\n",
       "       (228, 312, 110, 2, 3.5, 3. , 8.53, 0, 0.64),\n",
       "       (229, 318, 112, 3, 4. , 3.5, 8.67, 0, 0.71),\n",
       "       (230, 324, 111, 4, 3. , 3. , 9.01, 1, 0.82),\n",
       "       (231, 313, 104, 3, 4. , 4.5, 8.65, 0, 0.73),\n",
       "       (232, 319, 106, 3, 3.5, 2.5, 8.33, 1, 0.74),\n",
       "       (233, 312, 107, 2, 2.5, 3.5, 8.27, 0, 0.69),\n",
       "       (234, 304, 100, 2, 2.5, 3.5, 8.07, 0, 0.64),\n",
       "       (235, 330, 113, 5, 5. , 4. , 9.31, 1, 0.91),\n",
       "       (236, 326, 111, 5, 4.5, 4. , 9.23, 1, 0.88),\n",
       "       (237, 325, 112, 4, 4. , 4.5, 9.17, 1, 0.85),\n",
       "       (238, 329, 114, 5, 4.5, 5. , 9.19, 1, 0.86),\n",
       "       (239, 310, 104, 3, 2. , 3.5, 8.37, 0, 0.7 ),\n",
       "       (240, 299, 100, 1, 1.5, 2. , 7.89, 0, 0.59),\n",
       "       (241, 296, 101, 1, 2.5, 3. , 7.68, 0, 0.6 ),\n",
       "       (242, 317, 103, 2, 2.5, 2. , 8.15, 0, 0.65),\n",
       "       (243, 324, 115, 3, 3.5, 3. , 8.76, 1, 0.7 ),\n",
       "       (244, 325, 114, 3, 3.5, 3. , 9.04, 1, 0.76),\n",
       "       (245, 314, 107, 2, 2.5, 4. , 8.56, 0, 0.63),\n",
       "       (246, 328, 110, 4, 4. , 2.5, 9.02, 1, 0.81),\n",
       "       (247, 316, 105, 3, 3. , 3.5, 8.73, 0, 0.72),\n",
       "       (248, 311, 104, 2, 2.5, 3.5, 8.48, 0, 0.71),\n",
       "       (249, 324, 110, 3, 3.5, 4. , 8.87, 1, 0.8 ),\n",
       "       (250, 321, 111, 3, 3.5, 4. , 8.83, 1, 0.77),\n",
       "       (251, 320, 104, 3, 3. , 2.5, 8.57, 1, 0.74),\n",
       "       (252, 316,  99, 2, 2.5, 3. , 9.  , 0, 0.7 ),\n",
       "       (253, 318, 100, 2, 2.5, 3.5, 8.54, 1, 0.71),\n",
       "       (254, 335, 115, 4, 4.5, 4.5, 9.68, 1, 0.93),\n",
       "       (255, 321, 114, 4, 4. , 5. , 9.12, 0, 0.85),\n",
       "       (256, 307, 110, 4, 4. , 4.5, 8.37, 0, 0.79),\n",
       "       (257, 309,  99, 3, 4. , 4. , 8.56, 0, 0.76),\n",
       "       (258, 324, 100, 3, 4. , 5. , 8.64, 1, 0.78),\n",
       "       (259, 326, 102, 4, 5. , 5. , 8.76, 1, 0.77),\n",
       "       (260, 331, 119, 4, 5. , 4.5, 9.34, 1, 0.9 ),\n",
       "       (261, 327, 108, 5, 5. , 3.5, 9.13, 1, 0.87),\n",
       "       (262, 312, 104, 3, 3.5, 4. , 8.09, 0, 0.71),\n",
       "       (263, 308, 103, 2, 2.5, 4. , 8.36, 1, 0.7 ),\n",
       "       (264, 324, 111, 3, 2.5, 1.5, 8.79, 1, 0.7 ),\n",
       "       (265, 325, 110, 2, 3. , 2.5, 8.76, 1, 0.75),\n",
       "       (266, 313, 102, 3, 2.5, 2.5, 8.68, 0, 0.71),\n",
       "       (267, 312, 105, 2, 2. , 2.5, 8.45, 0, 0.72),\n",
       "       (268, 314, 107, 3, 3. , 3.5, 8.17, 1, 0.73),\n",
       "       (269, 327, 113, 4, 4.5, 5. , 9.14, 0, 0.83),\n",
       "       (270, 308, 108, 4, 4.5, 5. , 8.34, 0, 0.77),\n",
       "       (271, 306, 105, 2, 2.5, 3. , 8.22, 1, 0.72),\n",
       "       (272, 299,  96, 2, 1.5, 2. , 7.86, 0, 0.54),\n",
       "       (273, 294,  95, 1, 1.5, 1.5, 7.64, 0, 0.49),\n",
       "       (274, 312,  99, 1, 1. , 1.5, 8.01, 1, 0.52),\n",
       "       (275, 315, 100, 1, 2. , 2.5, 7.95, 0, 0.58),\n",
       "       (276, 322, 110, 3, 3.5, 3. , 8.96, 1, 0.78),\n",
       "       (277, 329, 113, 5, 5. , 4.5, 9.45, 1, 0.89),\n",
       "       (278, 320, 101, 2, 2.5, 3. , 8.62, 0, 0.7 ),\n",
       "       (279, 308, 103, 2, 3. , 3.5, 8.49, 0, 0.66),\n",
       "       (280, 304, 102, 2, 3. , 4. , 8.73, 0, 0.67),\n",
       "       (281, 311, 102, 3, 4.5, 4. , 8.64, 1, 0.68),\n",
       "       (282, 317, 110, 3, 4. , 4.5, 9.11, 1, 0.8 ),\n",
       "       (283, 312, 106, 3, 4. , 3.5, 8.79, 1, 0.81),\n",
       "       (284, 321, 111, 3, 2.5, 3. , 8.9 , 1, 0.8 ),\n",
       "       (285, 340, 112, 4, 5. , 4.5, 9.66, 1, 0.94),\n",
       "       (286, 331, 116, 5, 4. , 4. , 9.26, 1, 0.93),\n",
       "       (287, 336, 118, 5, 4.5, 4. , 9.19, 1, 0.92),\n",
       "       (288, 324, 114, 5, 5. , 4.5, 9.08, 1, 0.89),\n",
       "       (289, 314, 104, 4, 5. , 5. , 9.02, 0, 0.82),\n",
       "       (290, 313, 109, 3, 4. , 3.5, 9.  , 0, 0.79),\n",
       "       (291, 307, 105, 2, 2.5, 3. , 7.65, 0, 0.58),\n",
       "       (292, 300, 102, 2, 1.5, 2. , 7.87, 0, 0.56),\n",
       "       (293, 302,  99, 2, 1. , 2. , 7.97, 0, 0.56),\n",
       "       (294, 312,  98, 1, 3.5, 3. , 8.18, 1, 0.64),\n",
       "       (295, 316, 101, 2, 2.5, 2. , 8.32, 1, 0.61),\n",
       "       (296, 317, 100, 2, 3. , 2.5, 8.57, 0, 0.68),\n",
       "       (297, 310, 107, 3, 3.5, 3.5, 8.67, 0, 0.76),\n",
       "       (298, 320, 120, 3, 4. , 4.5, 9.11, 0, 0.86),\n",
       "       (299, 330, 114, 3, 4.5, 4.5, 9.24, 1, 0.9 ),\n",
       "       (300, 305, 112, 3, 3. , 3.5, 8.65, 0, 0.71),\n",
       "       (301, 309, 106, 2, 2.5, 2.5, 8.  , 0, 0.62),\n",
       "       (302, 319, 108, 2, 2.5, 3. , 8.76, 0, 0.66),\n",
       "       (303, 322, 105, 2, 3. , 3. , 8.45, 1, 0.65),\n",
       "       (304, 323, 107, 3, 3.5, 3.5, 8.55, 1, 0.73),\n",
       "       (305, 313, 106, 2, 2.5, 2. , 8.43, 0, 0.62),\n",
       "       (306, 321, 109, 3, 3.5, 3.5, 8.8 , 1, 0.74),\n",
       "       (307, 323, 110, 3, 4. , 3.5, 9.1 , 1, 0.79),\n",
       "       (308, 325, 112, 4, 4. , 4. , 9.  , 1, 0.8 ),\n",
       "       (309, 312, 108, 3, 3.5, 3. , 8.53, 0, 0.69),\n",
       "       (310, 308, 110, 4, 3.5, 3. , 8.6 , 0, 0.7 ),\n",
       "       (311, 320, 104, 3, 3. , 3.5, 8.74, 1, 0.76),\n",
       "       (312, 328, 108, 4, 4.5, 4. , 9.18, 1, 0.84),\n",
       "       (313, 311, 107, 4, 4.5, 4.5, 9.  , 1, 0.78),\n",
       "       (314, 301, 100, 3, 3.5, 3. , 8.04, 0, 0.67),\n",
       "       (315, 305, 105, 2, 3. , 4. , 8.13, 0, 0.66),\n",
       "       (316, 308, 104, 2, 2.5, 3. , 8.07, 0, 0.65),\n",
       "       (317, 298, 101, 2, 1.5, 2. , 7.86, 0, 0.54),\n",
       "       (318, 300,  99, 1, 1. , 2.5, 8.01, 0, 0.58),\n",
       "       (319, 324, 111, 3, 2.5, 2. , 8.8 , 1, 0.79),\n",
       "       (320, 327, 113, 4, 3.5, 3. , 8.69, 1, 0.8 ),\n",
       "       (321, 317, 106, 3, 4. , 3.5, 8.5 , 1, 0.75),\n",
       "       (322, 323, 104, 3, 4. , 4. , 8.44, 1, 0.73),\n",
       "       (323, 314, 107, 2, 2.5, 4. , 8.27, 0, 0.72),\n",
       "       (324, 305, 102, 2, 2. , 2.5, 8.18, 0, 0.62),\n",
       "       (325, 315, 104, 3, 3. , 2.5, 8.33, 0, 0.67),\n",
       "       (326, 326, 116, 3, 3.5, 4. , 9.14, 1, 0.81),\n",
       "       (327, 299, 100, 3, 2. , 2. , 8.02, 0, 0.63),\n",
       "       (328, 295, 101, 2, 2.5, 2. , 7.86, 0, 0.69),\n",
       "       (329, 324, 112, 4, 4. , 3.5, 8.77, 1, 0.8 ),\n",
       "       (330, 297,  96, 2, 2.5, 1.5, 7.89, 0, 0.43),\n",
       "       (331, 327, 113, 3, 3.5, 3. , 8.66, 1, 0.8 ),\n",
       "       (332, 311, 105, 2, 3. , 2. , 8.12, 1, 0.73),\n",
       "       (333, 308, 106, 3, 3.5, 2.5, 8.21, 1, 0.75),\n",
       "       (334, 319, 108, 3, 3. , 3.5, 8.54, 1, 0.71),\n",
       "       (335, 312, 107, 4, 4.5, 4. , 8.65, 1, 0.73),\n",
       "       (336, 325, 111, 4, 4. , 4.5, 9.11, 1, 0.83),\n",
       "       (337, 319, 110, 3, 3. , 2.5, 8.79, 0, 0.72),\n",
       "       (338, 332, 118, 5, 5. , 5. , 9.47, 1, 0.94),\n",
       "       (339, 323, 108, 5, 4. , 4. , 8.74, 1, 0.81),\n",
       "       (340, 324, 107, 5, 3.5, 4. , 8.66, 1, 0.81),\n",
       "       (341, 312, 107, 3, 3. , 3. , 8.46, 1, 0.75),\n",
       "       (342, 326, 110, 3, 3.5, 3.5, 8.76, 1, 0.79),\n",
       "       (343, 308, 106, 3, 3. , 3. , 8.24, 0, 0.58),\n",
       "       (344, 305, 103, 2, 2.5, 3.5, 8.13, 0, 0.59),\n",
       "       (345, 295,  96, 2, 1.5, 2. , 7.34, 0, 0.47),\n",
       "       (346, 316,  98, 1, 1.5, 2. , 7.43, 0, 0.49),\n",
       "       (347, 304,  97, 2, 1.5, 2. , 7.64, 0, 0.47),\n",
       "       (348, 299,  94, 1, 1. , 1. , 7.34, 0, 0.42),\n",
       "       (349, 302,  99, 1, 2. , 2. , 7.25, 0, 0.57),\n",
       "       (350, 313, 101, 3, 2.5, 3. , 8.04, 0, 0.62),\n",
       "       (351, 318, 107, 3, 3. , 3.5, 8.27, 1, 0.74),\n",
       "       (352, 325, 110, 4, 3.5, 4. , 8.67, 1, 0.73),\n",
       "       (353, 303, 100, 2, 3. , 3.5, 8.06, 1, 0.64),\n",
       "       (354, 300, 102, 3, 3.5, 2.5, 8.17, 0, 0.63),\n",
       "       (355, 297,  98, 2, 2.5, 3. , 7.67, 0, 0.59),\n",
       "       (356, 317, 106, 2, 2. , 3.5, 8.12, 0, 0.73),\n",
       "       (357, 327, 109, 3, 3.5, 4. , 8.77, 1, 0.79),\n",
       "       (358, 301, 104, 2, 3.5, 3.5, 7.89, 1, 0.68),\n",
       "       (359, 314, 105, 2, 2.5, 2. , 7.64, 0, 0.7 ),\n",
       "       (360, 321, 107, 2, 2. , 1.5, 8.44, 0, 0.81),\n",
       "       (361, 322, 110, 3, 4. , 5. , 8.64, 1, 0.85),\n",
       "       (362, 334, 116, 4, 4. , 3.5, 9.54, 1, 0.93),\n",
       "       (363, 338, 115, 5, 4.5, 5. , 9.23, 1, 0.91),\n",
       "       (364, 306, 103, 2, 2.5, 3. , 8.36, 0, 0.69),\n",
       "       (365, 313, 102, 3, 3.5, 4. , 8.9 , 1, 0.77),\n",
       "       (366, 330, 114, 4, 4.5, 3. , 9.17, 1, 0.86),\n",
       "       (367, 320, 104, 3, 3.5, 4.5, 8.34, 1, 0.74),\n",
       "       (368, 311,  98, 1, 1. , 2.5, 7.46, 0, 0.57),\n",
       "       (369, 298,  92, 1, 2. , 2. , 7.88, 0, 0.51),\n",
       "       (370, 301,  98, 1, 2. , 3. , 8.03, 1, 0.67),\n",
       "       (371, 310, 103, 2, 2.5, 2.5, 8.24, 0, 0.72),\n",
       "       (372, 324, 110, 3, 3.5, 3. , 9.22, 1, 0.89),\n",
       "       (373, 336, 119, 4, 4.5, 4. , 9.62, 1, 0.95),\n",
       "       (374, 321, 109, 3, 3. , 3. , 8.54, 1, 0.79),\n",
       "       (375, 315, 105, 2, 2. , 2.5, 7.65, 0, 0.39),\n",
       "       (376, 304, 101, 2, 2. , 2.5, 7.66, 0, 0.38),\n",
       "       (377, 297,  96, 2, 2.5, 2. , 7.43, 0, 0.34),\n",
       "       (378, 290, 100, 1, 1.5, 2. , 7.56, 0, 0.47),\n",
       "       (379, 303,  98, 1, 2. , 2.5, 7.65, 0, 0.56),\n",
       "       (380, 311,  99, 1, 2.5, 3. , 8.43, 1, 0.71),\n",
       "       (381, 322, 104, 3, 3.5, 4. , 8.84, 1, 0.78),\n",
       "       (382, 319, 105, 3, 3. , 3.5, 8.67, 1, 0.73),\n",
       "       (383, 324, 110, 4, 4.5, 4. , 9.15, 1, 0.82),\n",
       "       (384, 300, 100, 3, 3. , 3.5, 8.26, 0, 0.62),\n",
       "       (385, 340, 113, 4, 5. , 5. , 9.74, 1, 0.96),\n",
       "       (386, 335, 117, 5, 5. , 5. , 9.82, 1, 0.96),\n",
       "       (387, 302, 101, 2, 2.5, 3.5, 7.96, 0, 0.46),\n",
       "       (388, 307, 105, 2, 2. , 3.5, 8.1 , 0, 0.53),\n",
       "       (389, 296,  97, 2, 1.5, 2. , 7.8 , 0, 0.49),\n",
       "       (390, 320, 108, 3, 3.5, 4. , 8.44, 1, 0.76),\n",
       "       (391, 314, 102, 2, 2. , 2.5, 8.24, 0, 0.64),\n",
       "       (392, 318, 106, 3, 2. , 3. , 8.65, 0, 0.71),\n",
       "       (393, 326, 112, 4, 4. , 3.5, 9.12, 1, 0.84),\n",
       "       (394, 317, 104, 2, 3. , 3. , 8.76, 0, 0.77),\n",
       "       (395, 329, 111, 4, 4.5, 4. , 9.23, 1, 0.89),\n",
       "       (396, 324, 110, 3, 3.5, 3.5, 9.04, 1, 0.82),\n",
       "       (397, 325, 107, 3, 3. , 3.5, 9.11, 1, 0.84),\n",
       "       (398, 330, 116, 4, 5. , 4.5, 9.45, 1, 0.91),\n",
       "       (399, 312, 103, 3, 3.5, 4. , 8.78, 0, 0.67),\n",
       "       (400, 333, 117, 4, 5. , 4. , 9.66, 1, 0.95)],\n",
       "      dtype=[('serial_no', '<i8'), ('gre_score', '<i8'), ('toefl_score', '<i8'), ('university_rating', '<i8'), ('sop', '<f8'), ('lor', '<f8'), ('cgpa', '<f8'), ('research', '<i8'), ('chance_of_admission', '<f8')])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graduate_admission = np.genfromtxt('Admission_Predict.csv', dtype=None, \n",
    "                                   delimiter=',',skip_header=1,\n",
    "                                  names=('serial no','gre score','toefl score',\n",
    "                                        'university rating','sop','lor','cgpa','research','chance of admission'))\n",
    "\n",
    "graduate_admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graduate_admission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.65, 8.87, 8.  , 8.67, 8.21, 9.34, 8.2 ])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graduate_admission['cgpa'][0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-b902a50eef9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgraduate_admission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cgpa'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraduate_admission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cgpa'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgraduate_admission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cgpa'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "graduate_admission['cgpa'] = graduate_admission['cgpa']/10*4\n",
    "graduate_admission['cgpa'][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-c2d509ada254>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraduate_admission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraduate_admission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'research'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "len(graduate_admission[graduate_admission['research']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graduate_admission[[graduate_admission['chance_of_afmit']>0.8]['gre_score'].mean() 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
